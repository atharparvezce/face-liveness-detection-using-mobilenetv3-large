{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hRNU0xxFzHb"
      },
      "source": [
        "#0. Creating CSV file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jViVQiomF_5Q",
        "outputId": "cb5bafab-3a5a-4fbb-b588-9aef5307051f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "base_dir = \"/content/drive/MyDrive/face_liveness_rose\"\n",
        "videos_dir = f\"{base_dir}/videos_raw\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFjGLyHFGLPb",
        "outputId": "0017c15a-1e75-4e07-eeec-d2690f67cf33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing build_rose_youtu_csv.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile build_rose_youtu_csv.py\n",
        "# (paste your final working script here)\n",
        "\n",
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Build CSV metadata for the ROSE-Youtu Face Liveness dataset.\n",
        "\n",
        "Usage example:\n",
        "\n",
        "    python build_rose_youtu_csv.py \\\n",
        "        --videos_dir \"/Users/you/ROSE_Youtu/videos_raw\" \\\n",
        "        --output_csv \"/Users/you/ROSE_Youtu/rose_youtu_filelist.csv\"\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import re\n",
        "import argparse\n",
        "\n",
        "# Official training subject IDs from the protocol\n",
        "TRAIN_IDS = {2, 3, 4, 5, 6, 7, 9, 10, 11, 12}\n",
        "\n",
        "\n",
        "def get_attack_type(L: str) -> str:\n",
        "    \"\"\"Map the first token L to a human-readable attack type.\"\"\"\n",
        "    if L == \"G\":\n",
        "        return \"genuine\"\n",
        "    elif L in (\"Ps\", \"Pq\"):\n",
        "        return \"print\"\n",
        "    elif L in (\"Vl\", \"Vm\"):\n",
        "        return \"replay\"\n",
        "    elif L in (\"Mc\", \"Mf\", \"Mu\", \"Ml\"):\n",
        "        return \"mask\"\n",
        "    else:\n",
        "        return \"unknown\"\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description=\"Build ROSE-Youtu CSV metadata from videos.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--videos_dir\",\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help=\"Path to the folder containing all ROSE-Youtu videos (videos_raw).\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--output_csv\",\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help=\"Path where the output CSV will be saved.\",\n",
        "    )\n",
        "    return parser.parse_args()\n",
        "\n",
        "\n",
        "def main():\n",
        "    args = parse_args()\n",
        "    videos_dir = args.videos_dir\n",
        "    csv_path = args.output_csv\n",
        "\n",
        "    if not os.path.isdir(videos_dir):\n",
        "        raise FileNotFoundError(f\"videos_dir does not exist or is not a directory: {videos_dir}\")\n",
        "\n",
        "    rows = []\n",
        "    skipped = 0\n",
        "\n",
        "    print(f\"Scanning videos in: {videos_dir}\")\n",
        "\n",
        "    for root, dirs, files in os.walk(videos_dir):\n",
        "        for fname in files:\n",
        "            if not fname.lower().endswith(\".mp4\"):\n",
        "                continue\n",
        "\n",
        "            full_path = os.path.join(root, fname)\n",
        "            name = os.path.splitext(fname)[0]\n",
        "            parts = name.split(\"_\")\n",
        "\n",
        "            if len(parts) != 7:\n",
        "                print(f\"⚠️ Skipping unexpected name format ({len(parts)} parts): {fname}\")\n",
        "                skipped += 1\n",
        "                continue\n",
        "\n",
        "            L, S, D, X, E, p_token, N = parts\n",
        "\n",
        "            # Label: 1 = Real (G), 0 = Spoof\n",
        "            label = 1 if L == \"G\" else 0\n",
        "            attack_type = get_attack_type(L)\n",
        "\n",
        "            # Person ID:\n",
        "            # handle both \"p16\" and \"16\" styles\n",
        "            if p_token.startswith(\"p\"):\n",
        "                raw_pid = p_token[1:]\n",
        "            else:\n",
        "                raw_pid = p_token\n",
        "\n",
        "            pid_str = re.sub(r\"[^0-9]\", \"\", raw_pid)\n",
        "            if not pid_str:\n",
        "                print(f\"⚠️ Could not parse person id from '{p_token}' in {fname}\")\n",
        "                skipped += 1\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                person_id = int(pid_str)\n",
        "            except ValueError:\n",
        "                print(f\"⚠️ Invalid person id '{pid_str}' parsed from '{p_token}' in {fname}\")\n",
        "                skipped += 1\n",
        "                continue\n",
        "\n",
        "            # Train/test split by protocol\n",
        "            split = \"train\" if person_id in TRAIN_IDS else \"test\"\n",
        "\n",
        "            rows.append({\n",
        "                \"video_path\": os.path.abspath(full_path),\n",
        "                \"filename\": fname,\n",
        "                \"L\": L,\n",
        "                \"S\": S,\n",
        "                \"D\": D,\n",
        "                \"X\": X,\n",
        "                \"E\": E,\n",
        "                \"person_token\": p_token,\n",
        "                \"index_token\": N,\n",
        "                \"person_id\": person_id,\n",
        "                \"label\": label,          # 1 = Real, 0 = Spoof\n",
        "                \"attack_type\": attack_type,\n",
        "                \"split\": split\n",
        "            })\n",
        "\n",
        "    # Save to CSV\n",
        "    fieldnames = [\n",
        "        \"video_path\", \"filename\",\n",
        "        \"L\", \"S\", \"D\", \"X\", \"E\",\n",
        "        \"person_token\", \"index_token\",\n",
        "        \"person_id\", \"label\", \"attack_type\", \"split\"\n",
        "    ]\n",
        "\n",
        "    os.makedirs(os.path.dirname(csv_path) or \".\", exist_ok=True)\n",
        "\n",
        "    with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for r in rows:\n",
        "            writer.writerow(r)\n",
        "\n",
        "    print(\"\\n✅ Done.\")\n",
        "    print(f\"  Videos found & written: {len(rows)}\")\n",
        "    print(f\"  Videos skipped (bad names etc.): {skipped}\")\n",
        "    print(f\"  CSV saved to: {csv_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8PRyRihGRGX",
        "outputId": "8c044fde-564c-4889-c6b1-7e23f57ae1fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scanning videos in: /content/drive/MyDrive/face_liveness_rose/videos_raw\n",
            "\n",
            "✅ Done.\n",
            "  Videos found & written: 3497\n",
            "  Videos skipped (bad names etc.): 0\n",
            "  CSV saved to: /content/drive/MyDrive/face_liveness_rose/metadata/rose_youtu_filelist.csv\n"
          ]
        }
      ],
      "source": [
        "!python build_rose_youtu_csv.py \\\n",
        "  --videos_dir \"$videos_dir\" \\\n",
        "  --output_csv \"$base_dir/metadata/rose_youtu_filelist.csv\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "856H6HFYGVRD",
        "outputId": "d08437d6-7388-4509-a8ac-10490e1e11b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                          video_path                 filename  \\\n",
            "0  /content/drive/MyDrive/face_liveness_rose/vide...  Vm_NT_HW_g_E_22_169.mp4   \n",
            "1  /content/drive/MyDrive/face_liveness_rose/vide...   G_NT_HS_wg_E_23_10.mp4   \n",
            "2  /content/drive/MyDrive/face_liveness_rose/vide...    G_NT_5s_wg_E_23_5.mp4   \n",
            "3  /content/drive/MyDrive/face_liveness_rose/vide...    G_NT_5s_wg_E_23_2.mp4   \n",
            "4  /content/drive/MyDrive/face_liveness_rose/vide...  Vl_NT_HW_g_E_22_149.mp4   \n",
            "\n",
            "    L   S   D   X  E  person_token  index_token  person_id  label attack_type  \\\n",
            "0  Vm  NT  HW   g  E            22          169         22      0      replay   \n",
            "1   G  NT  HS  wg  E            23           10         23      1     genuine   \n",
            "2   G  NT  5s  wg  E            23            5         23      1     genuine   \n",
            "3   G  NT  5s  wg  E            23            2         23      1     genuine   \n",
            "4  Vl  NT  HW   g  E            22          149         22      0      replay   \n",
            "\n",
            "  split  \n",
            "0  test  \n",
            "1  test  \n",
            "2  test  \n",
            "3  test  \n",
            "4  test  \n",
            "label\n",
            "0    2600\n",
            "1     897\n",
            "Name: count, dtype: int64\n",
            "split\n",
            "test     1749\n",
            "train    1748\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "csv_path = f\"{base_dir}/metadata/rose_youtu_filelist.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "print(df.head())\n",
        "print(df['label'].value_counts())\n",
        "print(df['split'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_QCQhnnEUvQ"
      },
      "source": [
        "#1. Imports & basic setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhbTIEpeGalV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import random\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erxFn7C-Efj4"
      },
      "source": [
        "#2. Define transforms (for MobileNetV3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Dj6l382Eb4c"
      },
      "outputs": [],
      "source": [
        "# ImageNet mean/std (same you used before)\n",
        "imagenet_mean = [0.485, 0.456, 0.406]\n",
        "imagenet_std  = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmPsDD4NEpDd"
      },
      "source": [
        "# 3. Create the train/test DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXBe_QlMEjFs",
        "outputId": "803f4135-65b8-4ef7-bd8d-4b406cb6266b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1748, 1749)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df = df[df[\"split\"] == \"train\"].reset_index(drop=True)\n",
        "test_df  = df[df[\"split\"] == \"test\"].reset_index(drop=True)\n",
        "\n",
        "len(train_df), len(test_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94z1Iac8EtUm"
      },
      "source": [
        "#4. PyTorch Dataset: sample one random frame per video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5739h6JEqj_"
      },
      "outputs": [],
      "source": [
        "class RoseYoutuFrameDataset(Dataset):\n",
        "    def __init__(self, df, transform=None, max_attempts=5):\n",
        "        \"\"\"\n",
        "        df: pandas DataFrame with columns ['video_path', 'label', ...]\n",
        "        transform: torchvision transforms to apply to each frame\n",
        "        max_attempts: how many times to try reading a valid frame before giving up\n",
        "        \"\"\"\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "        self.max_attempts = max_attempts\n",
        "\n",
        "    def __len__(self):\n",
        "        # One sample = one video (we pick a random frame each time)\n",
        "        return len(self.df)\n",
        "\n",
        "    def _read_random_frame(self, video_path):\n",
        "        \"\"\"Open a video and return a random frame as a PIL.Image.\"\"\"\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        if not cap.isOpened():\n",
        "            raise RuntimeError(f\"Failed to open video: {video_path}\")\n",
        "\n",
        "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        if frame_count <= 0:\n",
        "            cap.release()\n",
        "            raise RuntimeError(f\"No frames found in video: {video_path}\")\n",
        "\n",
        "        # choose random frame index\n",
        "        frame_idx = random.randint(0, frame_count - 1)\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
        "        ret, frame = cap.read()\n",
        "        cap.release()\n",
        "\n",
        "        if not ret or frame is None:\n",
        "            raise RuntimeError(f\"Failed to read frame {frame_idx} from {video_path}\")\n",
        "\n",
        "        # OpenCV gives BGR, convert to RGB\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        img = Image.fromarray(frame)\n",
        "        return img\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        video_path = row[\"video_path\"]\n",
        "        label = int(row[\"label\"])  # 0 = spoof, 1 = real\n",
        "\n",
        "        # retry mechanism in case a random frame is bad\n",
        "        last_exception = None\n",
        "        for _ in range(self.max_attempts):\n",
        "            try:\n",
        "                img = self._read_random_frame(video_path)\n",
        "                break\n",
        "            except Exception as e:\n",
        "                last_exception = e\n",
        "                continue\n",
        "        else:\n",
        "            # if all attempts failed:\n",
        "            raise last_exception if last_exception is not None else RuntimeError(\n",
        "                f\"Could not read any frame from {video_path}\"\n",
        "            )\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxFsN_XcFqOv"
      },
      "source": [
        "#5. Create Dataset + DataLoader objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzjRanpcFpxk"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_dataset = RoseYoutuFrameDataset(train_df, transform=train_transform)\n",
        "test_dataset  = RoseYoutuFrameDataset(test_df,  transform=val_transform)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=2,      # you can try 2–4; if errors on Colab, set to 0\n",
        "    pin_memory=True,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erDTHEFfE1W7"
      },
      "source": [
        "#6. Sanity check: iterate one batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZyBQCa1ExeU",
        "outputId": "dcb6d7e3-12b8-4f70-af3c-f3352d9315ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Images shape: torch.Size([32, 3, 224, 224])\n",
            "Labels shape: torch.Size([32])\n",
            "Labels: tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0])\n"
          ]
        }
      ],
      "source": [
        "batch = next(iter(train_loader))\n",
        "images, labels = batch\n",
        "\n",
        "print(\"Images shape:\", images.shape)   # expected: [batch_size, 3, 224, 224]\n",
        "print(\"Labels shape:\", labels.shape)   # expected: [batch_size]\n",
        "print(\"Labels:\", labels[:10])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-67RMumiGL4W"
      },
      "source": [
        "#7. Load MobileNetV3-Large (Pretrained)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KUE_3goGOW5",
        "outputId": "2482bce8-2c93-47cb-fa1b-7dd5a1d3fec1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_large-8738ca79.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21.1M/21.1M [00:00<00:00, 73.6MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MobileNetV3(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2dNormActivation(\n",
            "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (2): Hardswish()\n",
            "    )\n",
            "    (1): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
            "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
            "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Conv2dNormActivation(\n",
            "          (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
            "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Conv2dNormActivation(\n",
            "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (4): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
            "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (5): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
            "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (6): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
            "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (7): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
            "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): Conv2dNormActivation(\n",
            "          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (8): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
            "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): Conv2dNormActivation(\n",
            "          (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (9): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
            "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): Conv2dNormActivation(\n",
            "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (10): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
            "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): Conv2dNormActivation(\n",
            "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (11): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
            "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (12): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (13): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
            "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (14): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
            "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (15): InvertedResidual(\n",
            "      (block): Sequential(\n",
            "        (0): Conv2dNormActivation(\n",
            "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (1): Conv2dNormActivation(\n",
            "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
            "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          (2): Hardswish()\n",
            "        )\n",
            "        (2): SqueezeExcitation(\n",
            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (activation): ReLU()\n",
            "          (scale_activation): Hardsigmoid()\n",
            "        )\n",
            "        (3): Conv2dNormActivation(\n",
            "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (16): Conv2dNormActivation(\n",
            "      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "      (2): Hardswish()\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=960, out_features=1280, bias=True)\n",
            "    (1): Hardswish()\n",
            "    (2): Dropout(p=0.2, inplace=True)\n",
            "    (3): Linear(in_features=1280, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Load pretrained MobileNetV3-Large\n",
        "model = models.mobilenet_v3_large(weights=models.MobileNet_V3_Large_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Modify final classifier layer → output 1 logit (binary)\n",
        "in_features = model.classifier[-1].in_features\n",
        "model.classifier[-1] = nn.Linear(in_features, 1)\n",
        "\n",
        "model = model.to(device)\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4JCDHlKGW6U"
      },
      "source": [
        "#8. Define Loss Function + Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eenvyz4PGPnE"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=1e-4,         # good starting LR\n",
        "    weight_decay=1e-5\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEV1OTInGb2N"
      },
      "source": [
        "#9. Training Loop (Simple & Clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhqMbqCBGZpp"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.float().to(device)  # BCE needs float\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images).squeeze(1)   # [batch] shape\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * images.size(0)\n",
        "\n",
        "        # Predictions: sigmoid → threshold 0.5\n",
        "        preds = (torch.sigmoid(outputs) >= 0.5).long()\n",
        "        total_correct += (preds.cpu() == labels.cpu().long()).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    accuracy = total_correct / total_samples\n",
        "\n",
        "    return avg_loss, accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8GG3QAeGfRt"
      },
      "source": [
        "#10. Validation Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9KH5ljpGeXh"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.float().to(device)\n",
        "\n",
        "            outputs = model(images).squeeze(1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "\n",
        "            preds = (torch.sigmoid(outputs) >= 0.5).long()\n",
        "            total_correct += (preds.cpu() == labels.cpu().long()).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    accuracy = total_correct / total_samples\n",
        "\n",
        "    return avg_loss, accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oau6MAkPGkg5"
      },
      "source": [
        "#11. Main Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7KDmVqiGj9w",
        "outputId": "e1be12d3-6197-400d-d039-60e59bb8e3a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "  Train Loss: 0.2343 | Train Acc: 0.9027\n",
            "  Val   Loss: 0.0535 | Val   Acc: 0.9846\n",
            "Epoch 2/10\n",
            "  Train Loss: 0.0209 | Train Acc: 0.9943\n",
            "  Val   Loss: 0.0628 | Val   Acc: 0.9737\n",
            "Epoch 3/10\n",
            "  Train Loss: 0.0215 | Train Acc: 0.9943\n",
            "  Val   Loss: 0.0340 | Val   Acc: 0.9891\n",
            "Epoch 4/10\n",
            "  Train Loss: 0.0101 | Train Acc: 0.9971\n",
            "  Val   Loss: 0.0588 | Val   Acc: 0.9817\n",
            "Epoch 5/10\n",
            "  Train Loss: 0.0040 | Train Acc: 0.9994\n",
            "  Val   Loss: 0.0141 | Val   Acc: 0.9960\n",
            "Epoch 6/10\n",
            "  Train Loss: 0.0019 | Train Acc: 1.0000\n",
            "  Val   Loss: 0.0199 | Val   Acc: 0.9937\n",
            "Epoch 7/10\n",
            "  Train Loss: 0.0028 | Train Acc: 0.9994\n",
            "  Val   Loss: 0.0173 | Val   Acc: 0.9937\n",
            "Epoch 8/10\n",
            "  Train Loss: 0.0016 | Train Acc: 1.0000\n",
            "  Val   Loss: 0.0264 | Val   Acc: 0.9914\n",
            "Epoch 9/10\n",
            "  Train Loss: 0.0009 | Train Acc: 1.0000\n",
            "  Val   Loss: 0.0179 | Val   Acc: 0.9937\n",
            "Epoch 10/10\n",
            "  Train Loss: 0.0098 | Train Acc: 0.9954\n",
            "  Val   Loss: 0.0676 | Val   Acc: 0.9806\n"
          ]
        }
      ],
      "source": [
        "epochs = 10   # we can increase later\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_accs = []\n",
        "test_accs = []\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "    val_loss, val_acc = evaluate(model, test_loader, criterion, device)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    test_losses.append(val_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    test_accs.append(val_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch}/{epochs}\")\n",
        "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "    print(f\"  Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnGeTQxlGqBe"
      },
      "source": [
        "#12. Save Your Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9I7GGwGbGo3w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03abc80a-e56b-4cc4-efa2-e7929e6c8bfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/face_liveness_rose/checkpoints/mobilenetv3_liveness.pth\n"
          ]
        }
      ],
      "source": [
        "save_path = f\"{base_dir}/checkpoints/mobilenetv3_liveness.pth\"\n",
        "os.makedirs(f\"{base_dir}/checkpoints\", exist_ok=True)\n",
        "torch.save(model.state_dict(), save_path)\n",
        "\n",
        "print(\"Model saved to:\", save_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}